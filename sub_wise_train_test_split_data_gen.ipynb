{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-22T09:06:41.800094739Z",
     "start_time": "2023-11-22T08:54:11.799442838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_train.pkl', '2_train.pkl', '3_train.pkl', '4_train.pkl', '5_train.pkl']\n",
      "['1_test.pkl', '2_test.pkl', '3_test.pkl', '4_test.pkl', '5_test.pkl']\n",
      "For subject: 1\n",
      "For file : 1_train.pkl\n",
      "Number of samples in the file: 1320\n",
      "(1320, 8, 1000)\n",
      "(1320, 14382)\n",
      "For subject: 2\n",
      "For file : 2_train.pkl\n",
      "Number of samples in the file: 1320\n",
      "(1320, 8, 1000)\n",
      "(1320, 13497)\n",
      "For subject: 3\n",
      "For file : 3_train.pkl\n",
      "Number of samples in the file: 1320\n",
      "(1320, 8, 1000)\n",
      "(1320, 14514)\n",
      "For subject: 4\n",
      "For file : 4_train.pkl\n",
      "Number of samples in the file: 1320\n",
      "(1320, 8, 1000)\n",
      "(1320, 12867)\n",
      "For subject: 5\n",
      "For file : 5_train.pkl\n",
      "Number of samples in the file: 1320\n",
      "(1320, 8, 1000)\n",
      "(1320, 13440)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184592/2469803136.py:68: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  total_Y_train=np.array(total_Y_train)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1320,14382) into shape (1320,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 68\u001B[0m\n\u001B[1;32m     65\u001B[0m         total_Y_train\u001B[38;5;241m.\u001B[39mappend(per_sub_y_train)\n\u001B[1;32m     67\u001B[0m total_X_train\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray(total_X_train)\n\u001B[0;32m---> 68\u001B[0m total_Y_train\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_Y_train\u001B[49m\u001B[43m)\u001B[49m  \n\u001B[1;32m     69\u001B[0m \u001B[38;5;28mprint\u001B[39m(total_X_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28mprint\u001B[39m(total_Y_train\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mValueError\u001B[0m: could not broadcast input array from shape (1320,14382) into shape (1320,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import slir\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_main_dir=\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/train/\"\n",
    "\n",
    "test_main_dir=\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/test/\"\n",
    "\n",
    "\n",
    "\n",
    "train_pkl_files=sorted(os.listdir(train_main_dir))\n",
    "test_pkl_files=sorted(os.listdir(test_main_dir))\n",
    "print(train_pkl_files)\n",
    "print(test_pkl_files)\n",
    "total_X_train=[]\n",
    "total_Y_train=[]\n",
    "for data_file_pth in train_pkl_files:\n",
    "    subject_number=int(data_file_pth[0])\n",
    "    print(\"For subject:\",subject_number)\n",
    "    print(\"For file :\",data_file_pth)\n",
    "    with (open(train_main_dir+data_file_pth, 'rb')as data_file):\n",
    "        list_of_data= pickle.load(data_file)\n",
    "        \n",
    "\n",
    "        per_sub_x_train=None\n",
    "        per_sub_y_train = None\n",
    "        print(\"Number of samples in the file:\",len(list_of_data))\n",
    "        for index,data_samples in enumerate(list_of_data):\n",
    "            fmri_1d_vector=data_samples[0]\n",
    "            dict_of_multi_layer_features=data_samples[1]\n",
    "            img_used=data_samples[2]\n",
    "            #print(\"\\t Index : \", index, \"running with Img_ID:\",img_used)\n",
    "            per_data_sample_x_data=None\n",
    "            \n",
    "            for layer_names in dict_of_multi_layer_features.keys():\n",
    "                layer=dict_of_multi_layer_features[layer_names].detach().cpu().numpy()\n",
    "                \n",
    "                layer = np.expand_dims(layer, 0)\n",
    "                # print(layer.shape)\n",
    "                if per_data_sample_x_data is None:\n",
    "                    per_data_sample_x_data=layer\n",
    "                else:\n",
    "                    per_data_sample_x_data = np.concatenate((per_data_sample_x_data,layer),axis=0)\n",
    "            \n",
    "            # print(per_data_sample_x_data.shape)\n",
    "            # print(fmri_1d_vector.shape)\n",
    "            per_data_sample_x_data = np.expand_dims(per_data_sample_x_data, 0)\n",
    "            #fmri_1d_vector = np.expand_dims(fmri_1d_vector, 0)\n",
    "            # print(per_data_sample_x_data.shape)\n",
    "            # print(fmri_1d_vector.shape)\n",
    "            \n",
    "            if per_sub_x_train is None and per_sub_y_train is None:\n",
    "                per_sub_x_train=per_data_sample_x_data\n",
    "                per_sub_y_train=fmri_1d_vector\n",
    "            else:\n",
    "                per_sub_x_train = np.concatenate((per_sub_x_train,per_data_sample_x_data),axis=0)\n",
    "                per_sub_y_train=np.concatenate((per_sub_y_train,fmri_1d_vector),axis=0)\n",
    "        print(per_sub_x_train.shape)\n",
    "        print(per_sub_y_train.shape)\n",
    "        total_X_train.append(per_sub_x_train)\n",
    "        total_Y_train.append(per_sub_y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(total_X_train.shape)\n",
    "print(total_Y_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 8, 1000)\n",
      "(1320, 14382)\n",
      "(1320, 8, 1000)\n",
      "(1320, 13497)\n",
      "(1320, 8, 1000)\n",
      "(1320, 14514)\n",
      "(1320, 8, 1000)\n",
      "(1320, 12867)\n",
      "(1320, 8, 1000)\n",
      "(1320, 13440)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subject in range(0,5):\n",
    "    with open(f\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/subject_{subject+1}_train_X_for_ann.pkl\", \"wb\") as train_save_X :\n",
    "        print(total_X_train[subject].shape)\n",
    "        pickle.dump(total_X_train[subject], train_save_X)\n",
    "    with open(f\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/subject_{subject+1}_train_Y_for_ann.pkl\", \"wb\") as train_save_Y :\n",
    "        print(total_Y_train[subject].shape)\n",
    "        pickle.dump(total_Y_train[subject], train_save_Y)   \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T09:35:06.613590759Z",
     "start_time": "2023-11-22T09:35:02.143269509Z"
    }
   },
   "id": "1c62fea1b7ddd3af"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_train.pkl', '2_train.pkl', '3_train.pkl', '4_train.pkl', '5_train.pkl']\n",
      "['1_test.pkl', '2_test.pkl', '3_test.pkl', '4_test.pkl', '5_test.pkl']\n",
      "1_test.pkl\n",
      "For subject: 1\n",
      "For file : 1_test.pkl\n",
      "(1320, 8, 1000)\n",
      "(1320, 14382)\n",
      "2_test.pkl\n",
      "For subject: 2\n",
      "For file : 2_test.pkl\n",
      "(1320, 8, 1000)\n",
      "(1320, 13497)\n",
      "3_test.pkl\n",
      "For subject: 3\n",
      "For file : 3_test.pkl\n",
      "(1320, 8, 1000)\n",
      "(1320, 14514)\n",
      "4_test.pkl\n",
      "For subject: 4\n",
      "For file : 4_test.pkl\n",
      "(1320, 8, 1000)\n",
      "(1320, 12867)\n",
      "5_test.pkl\n",
      "For subject: 5\n",
      "For file : 5_test.pkl\n",
      "(1210, 8, 1000)\n",
      "(1210, 13440)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_pkl_files=sorted(os.listdir(train_main_dir))\n",
    "test_pkl_files=sorted(os.listdir(test_main_dir))\n",
    "print(train_pkl_files)\n",
    "print(test_pkl_files)\n",
    "total_X_test=[]\n",
    "total_Y_test=[]\n",
    "for data_file_pth in test_pkl_files:\n",
    "    print(data_file_pth)\n",
    "    subject_number=int(data_file_pth[0])\n",
    "    print(\"For subject:\",subject_number)\n",
    "    print(\"For file :\",data_file_pth)\n",
    "    \n",
    "    with (open(test_main_dir+data_file_pth, 'rb')as data_file):\n",
    "        list_of_data= pickle.load(data_file)\n",
    "        \n",
    "\n",
    "        per_sub_x_train=None\n",
    "        per_sub_y_train = None\n",
    "        #print(\"Number of samples in the file:\",len(list_of_data))\n",
    "        for index,data_samples in enumerate(list_of_data):\n",
    "            fmri_1d_vector=data_samples[0]\n",
    "            dict_of_multi_layer_features=data_samples[1]\n",
    "            img_used=data_samples[2]\n",
    "            #print(\"\\t Index : \", index, \"running with Img_ID:\",img_used)\n",
    "            per_data_sample_x_data=None\n",
    "            \n",
    "            for layer_names in dict_of_multi_layer_features.keys():\n",
    "                layer=dict_of_multi_layer_features[layer_names].detach().cpu().numpy()\n",
    "                \n",
    "                layer = np.expand_dims(layer, 0)\n",
    "                # print(layer.shape)\n",
    "                if per_data_sample_x_data is None:\n",
    "                    per_data_sample_x_data=layer\n",
    "                else:\n",
    "                    per_data_sample_x_data = np.concatenate((per_data_sample_x_data,layer),axis=0)\n",
    "            \n",
    "            # print(per_data_sample_x_data.shape)\n",
    "            # print(fmri_1d_vector.shape)\n",
    "            per_data_sample_x_data = np.expand_dims(per_data_sample_x_data, 0)\n",
    "            #fmri_1d_vector = np.expand_dims(fmri_1d_vector, 0)\n",
    "            # print(per_data_sample_x_data.shape)\n",
    "            # print(fmri_1d_vector.shape)\n",
    "            \n",
    "            if per_sub_x_train is None and per_sub_y_train is None:\n",
    "                per_sub_x_train=per_data_sample_x_data\n",
    "                per_sub_y_train=fmri_1d_vector\n",
    "            else:\n",
    "                per_sub_x_train = np.concatenate((per_sub_x_train,per_data_sample_x_data),axis=0)\n",
    "                per_sub_y_train=np.concatenate((per_sub_y_train,fmri_1d_vector),axis=0)\n",
    "        print(per_sub_x_train.shape)\n",
    "        print(per_sub_y_train.shape)\n",
    "        total_X_test.append(per_sub_x_train)\n",
    "        total_Y_test.append(per_sub_y_train)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T11:08:09.531714328Z",
     "start_time": "2023-11-22T10:27:07.556558788Z"
    }
   },
   "id": "955ccd5d06004f92"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 8, 1000)\n",
      "(1320, 14382)\n",
      "(1320, 8, 1000)\n",
      "(1320, 13497)\n",
      "(1320, 8, 1000)\n",
      "(1320, 14514)\n",
      "(1320, 8, 1000)\n",
      "(1320, 12867)\n",
      "(1210, 8, 1000)\n",
      "(1210, 13440)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subject in range(0,5):\n",
    "    with open(f\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/subject_{subject+1}_test_X_for_ann.pkl\", \"wb\") as test_save_X :\n",
    "        print(total_X_test[subject].shape)\n",
    "        pickle.dump(total_X_test[subject], test_save_X)\n",
    "    with open(f\"/home/srinjoy/PycharmProjects/funfMRI/sub_wise_lin_reg_data/subject_{subject+1}_test_Y_for_ann.pkl\", \"wb\") as test_save_Y :\n",
    "        print(total_Y_test[subject].shape)\n",
    "        pickle.dump(total_Y_test[subject], test_save_Y)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T11:08:12.789111207Z",
     "start_time": "2023-11-22T11:08:09.528183344Z"
    }
   },
   "id": "e6f5973a8d03fbc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# X_train_data_for_slir = np.transpose(total_X_train, (1, 0, 2))\n",
    "# X_test_data_for_slir = np.transpose(total_X_test, (1, 0, 2))\n",
    "# # Print the shapes of the original and transposed arrays\n",
    "# print(\"X_train array shape:\", X_train_data_for_slir.shape)\n",
    "# print(\"X_test array shape:\", X_test_data_for_slir.shape)\n",
    "# with open(f\"/home/srinjoy/PycharmProjects/funfMRI/total_train_X_for_slir.pkl\", \"wb\") as train_slir_save_X :\n",
    "#     pickle.dump(X_train_data_for_slir, train_slir_save_X)\n",
    "# with open(f\"/home/srinjoy/PycharmProjects/funfMRI/total_test_X_for_slir.pkl\", \"wb\") as test_slir_save_X :\n",
    "#     pickle.dump(X_test_data_for_slir, test_slir_save_X)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7b30434bc022b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e79af8aaf67b09a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
